
# Broad Lessons From Boeing’s 737 MAX Greek Tragedy

Published at: **2019-11-01T00:00:00+00:00**

Author: **Hersh Shefrin**

Original: [Forbes](https://www.forbes.com/sites/hershshefrin/2019/10/31/broad-lessons-from-boeings-737-max-greek-tragedy/)

Boeing’s CEO Dennis Muilenburg is spending this week on Capitol Hill testifying before a series of Congressional committees about failures related to the 737 MAX. The saga of the 737 MAX is akin to a classic Greek tragedy featuring heroes with tragic flaws, along with a host of general lessons.
In respect to the phrase “tragic flaw,” the most salient problem in the 737 MAX is a feature known as MCAS, the faulty software system that seized control from pilots of two commercial 737 MAX flights, one from Indonesian airline Lion Air and the other from Ethiopian Airlines, causing both to crash.
This week, much attention is being paid to the culture at Boeing, especially its willingness to focus on profit at the expense of safety. Doing so is instructive, especially if we identify the broader psychological issues that impacted Boeing’s decision makers and which apply to decision makers at many firms.
The broad issues pertain to Boeing decision makers’ mindsets as they faced strong competitive pressures from Airbus. In part, this pressure arose because Boeing executives were late to recognize the Airbus threat, partly because of their own hubris. In particular, Boeing executives failed to put controls in place in order to manage normal human tendencies that arise when people feel themselves to be operating in the domain of losses. These human tendencies involve the inclination to take imprudent risks in an attempt to avoid having to accept a sure loss.  Just as unsuccessful racetrack bettors tend to back long shots late in the day, in the hope of breaking even, Boeing took risks with the 737 MAX by cutting corners, in an effort to avoid having to cede the market to Airbus.
Media coverage of the 737 MAX fiasco, such as by The New York Times and The Wall Street Journal has identified the nature of imprudent risks that Boeing took in developing the 737 MAX. The issues are varied. Boeing changed important features of MCAS after the original MCAS design had been approved by the FAA. Notably, the firm introduced a single point of sensor failure, without highlighting the changes. The firm also pursued an unrealistic strategy of minimizing simulator-based training for pilots on the 737 MAX. In this regard, it assessed the risk of pilots’ ability to address MCAS-based problems by relying on the reactions of its own test pilots as opposed to those of less skilled commercial airliner pilots. This week, CEO Muilenburg faced special criticism from lawmakers because his firm ignored messages from its own employees who warned about problems with MCAS.
Lying at the root of the behavior patterns described in the previous paragraph are a small number of psychological phenomena. The list includes excessive optimism, overconfidence, and confirmation bias: optimism for underestimating the probability of commercial airline pilots being able to deal with MCAS problems, overconfidence about the risks attached to allowing for a single point of failure, and confirmation bias by downplaying the problem after two 737 MAX planes had crashed.
Aversion to accepting a sure loss, excessive optimism, overconfidence, and confirmation bias are general phenomena that impact many organizations. Boeing’s experience is currently under scrutiny, but it is hardly unique. The firm’s missteps serve as a cautionary warning for all firms facing strong competitive pressures about the need to practice prudent risk management.
